# This file is used to manually specify the semi-automatic conversion of
# 'nipype.interfaces.afni.preprocess.TProject' from Nipype to Pydra.
#
# Please fill-in/edit the fields below where appropriate
#
# Inputs
# ------
# in_file : file
#    input file to 3dTproject
# out_file : file
#    output image file name
# censor : file
#    Filename of censor .1D time series. This is a file of 1s and 0s, indicating which time points are to be included (1) and which are to be excluded (0).
# censortr : list
#    List of strings that specify time indexes to be removed from the analysis.  Each string is of one of the following forms:  * ``37`` => remove global time index #37 * ``2:37`` => remove time index #37 in run #2 * ``37..47`` => remove global time indexes #37-47 * ``37-47`` => same as above * ``2:37..47`` => remove time indexes #37-47 in run #2 * ``*:0-2`` => remove time indexes #0-2 in all runs    * Time indexes within each run start at 0.   * Run indexes start at 1 (just be to confusing).   * N.B.: 2:37,47 means index #37 in run #2 and     global time index 47; it does NOT mean     index #37 in run #2 AND index #47 in run #2.  
# cenmode : enum
#    Specifies how censored time points are treated in the output dataset:  * mode = ZERO -- put zero values in their place;   output dataset is same length as input * mode = KILL -- remove those time points;   output dataset is shorter than input * mode = NTRP -- censored values are replaced by interpolated   neighboring (in time) non-censored values,   BEFORE any projections, and then the   analysis proceeds without actual removal   of any time points -- this feature is to   keep the Spanish Inquisition happy. * The default mode is KILL !!!  
# concat : file
#    The catenation file, as in 3dDeconvolve, containing the TR indexes of the start points for each contiguous run within the input dataset (the first entry should be 0).  * Also as in 3dDeconvolve, if the input dataset is   automatically catenated from a collection of datasets,   then the run start indexes are determined directly,   and '-concat' is not needed (and will be ignored). * Each run must have at least 9 time points AFTER   censoring, or the program will not work! * The only use made of this input is in setting up   the bandpass/stopband regressors. * '-ort' and '-dsort' regressors run through all time   points, as read in.  If you want separate projections   in each run, then you must either break these ort files   into appropriate components, OR you must run 3dTproject   for each run separately, using the appropriate pieces   from the ort files via the ``{...}`` selector for the   1D files and the ``[...]`` selector for the datasets.  
# noblock : bool
#    Also as in 3dDeconvolve, if you want the program to treat an auto-catenated dataset as one long run, use this option. However, '-noblock' will not affect catenation if you use the '-concat' option.
# ort : file
#    Remove each column in file. Each column will have its mean removed.
# polort : int
#    Remove polynomials up to and including degree pp.  * Default value is 2. * It makes no sense to use a value of pp greater than   2, if you are bandpassing out the lower frequencies! * For catenated datasets, each run gets a separate set   set of pp+1 Legendre polynomial regressors. * Use of -polort -1 is not advised (if data mean != 0),   even if -ort contains constant terms, as all means are   removed.  
# dsort : inputmultiobject
#    Remove the 3D+time time series in dataset fset.  * That is, 'fset' contains a different nuisance time   series for each voxel (e.g., from AnatICOR). * Multiple -dsort options are allowed.  
# bandpass : tuple
#    Remove all frequencies EXCEPT those in the range
# stopband : tuple
#    Remove all frequencies in the range
# TR : float
#    Use time step dd for the frequency calculations, rather than the value stored in the dataset header.
# mask : file
#    Only operate on voxels nonzero in the mset dataset.  * Voxels outside the mask will be filled with zeros. * If no masking option is given, then all voxels   will be processed.  
# automask : bool
#    Generate a mask automatically
# blur : float
#    Blur (inside the mask only) with a filter that has width (FWHM) of fff millimeters. Spatial blurring (if done) is after the time series filtering.
# norm : bool
#     Normalize each output time series to have sum of squares = 1. This is the LAST operation.
# num_threads : int
#    set number of threads
# outputtype : enum
#    AFNI output filetype
# args : str
#    Additional parameters to the command
# environ : dict
#    Environment variables
#
# Outputs
# -------
# out_file : file
#    output file
#
# Docs
# ----
# 
#     This program projects (detrends) out various 'nuisance' time series from
#     each voxel in the input dataset.  Note that all the projections are done
#     via linear regression, including the frequency-based options such
#     as ``-passband``.  In this way, you can bandpass time-censored data, and at
#     the same time, remove other time series of no interest
#     (e.g., physiological estimates, motion parameters).
#     Shifts voxel time series from input so that separate slices are aligned to
#     the same temporal origin.
# 
#     Examples
#     --------
#     >>> from nipype.interfaces import afni
#     >>> tproject = afni.TProject()
#     >>> tproject.inputs.in_file = 'functional.nii'
#     >>> tproject.inputs.bandpass = (0.00667, 99999)
#     >>> tproject.inputs.polort = 3
#     >>> tproject.inputs.automask = True
#     >>> tproject.inputs.out_file = 'projected.nii.gz'
#     >>> tproject.cmdline
#     '3dTproject -input functional.nii -automask -bandpass 0.00667 99999 -polort 3 -prefix projected.nii.gz'
#     >>> res = tproject.run()  # doctest: +SKIP
# 
#     See Also
#     --------
#     For complete details, see the `3dTproject Documentation.
#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dTproject.html>`__
# 
#     
task_name: t_project
nipype_name: TProject
nipype_module: nipype.interfaces.afni.preprocess
inputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    in_file: medimage/nifti1
    out_file: medimage/nifti-gz
    censor: generic/file
    concat: generic/file
    ort: generic/file
    dsort: generic/file+list-of
    mask: generic/file
  metadata:
  # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
outputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    out_file: medimage/nifti-gz
  callables:
  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
  # to set to the `callable` attribute of output fields
  templates:
  # dict[str, str] - `output_file_template` values to be provided to output fields
  requirements:
  # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
tests:
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    in_file:
    bandpass: (0.00667, 99999)
    polort: '3'
    automask: 'True'
    out_file:
  imports:
  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
doctests:
- cmdline: 3dTproject -input functional.nii -automask -bandpass 0.00667 99999 -polort 3 -prefix projected.nii.gz
  # str - the expected cmdline output
  inputs:
  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
  # If the field is of file-format type and the value is None, then the
  # '.mock()' method of the corresponding class is used instead.
    in_file:
    bandpass: (0.00667, 99999)
    polort: '3'
    automask: 'True'
    out_file:
  imports:
  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  directive: ''''
  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
