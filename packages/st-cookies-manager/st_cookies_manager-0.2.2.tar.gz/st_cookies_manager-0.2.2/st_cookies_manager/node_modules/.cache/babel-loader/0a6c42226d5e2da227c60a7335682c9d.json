{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\nexport function schemaFromJSON(_schema) {\n  let dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(f => Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce((fieldNodes, column) => [...fieldNodes, new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY'])), ...fieldNodesFromJSON(column['children'])], []);\n}\n/** @ignore */\nfunction buffersFromJSON(xs) {\n  let buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  for (let i = -1, n = (xs || []).length; ++i < n;) {\n    const column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n  return buffers;\n}\n/** @ignore */\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n/** @ignore */\nexport function fieldFromJSON(_field, dictionaries) {\n  let id;\n  let keys;\n  let field;\n  let dictMeta;\n  let type;\n  let dictType;\n  // If no dictionary encoding\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n  return field || null;\n}\n/** @ignore */\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\nfunction typeFromJSON(f, children) {\n  const typeId = f['type']['name'];\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n    case 'null':\n      return new Null();\n    case 'binary':\n      return new Binary();\n    case 'utf8':\n      return new Utf8();\n    case 'bool':\n      return new Bool();\n    case 'list':\n      return new List((children || [])[0]);\n    case 'struct':\n      return new Struct(children || []);\n    case 'struct_':\n      return new Struct(children || []);\n  }\n  switch (typeId) {\n    case 'int':\n      {\n        const t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n    case 'floatingpoint':\n      {\n        const t = f['type'];\n        return new Float(Precision[t['precision']]);\n      }\n    case 'decimal':\n      {\n        const t = f['type'];\n        return new Decimal(t['scale'], t['precision']);\n      }\n    case 'date':\n      {\n        const t = f['type'];\n        return new Date_(DateUnit[t['unit']]);\n      }\n    case 'time':\n      {\n        const t = f['type'];\n        return new Time(TimeUnit[t['unit']], t['bitWidth']);\n      }\n    case 'timestamp':\n      {\n        const t = f['type'];\n        return new Timestamp(TimeUnit[t['unit']], t['timezone']);\n      }\n    case 'interval':\n      {\n        const t = f['type'];\n        return new Interval(IntervalUnit[t['unit']]);\n      }\n    case 'union':\n      {\n        const t = f['type'];\n        return new Union(UnionMode[t['mode']], t['typeIds'] || [], children || []);\n      }\n    case 'fixedsizebinary':\n      {\n        const t = f['type'];\n        return new FixedSizeBinary(t['byteWidth']);\n      }\n    case 'fixedsizelist':\n      {\n        const t = f['type'];\n        return new FixedSizeList(t['listSize'], (children || [])[0]);\n      }\n    case 'map':\n      {\n        const t = f['type'];\n        return new Map_((children || [])[0], t['keysSorted']);\n      }\n  }\n  throw new Error(\"Unrecognized type: \\\"\".concat(typeId, \"\\\"\"));\n}","map":{"version":3,"sources":["ipc/metadata/json.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAS,MAAM,EAAE,KAAK,QAAQ,cAAc;AAC5C,SACc,UAAU,EACpB,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,eAAe,EACtC,IAAI,EAAE,aAAa,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EACxC,IAAI,EAAE,IAAI,EAAE,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,QAAQ,EAAE,SAAS,EAAe,KAAK,QACzE,YAAY;AAEnB,SAAS,eAAe,EAAE,WAAW,EAAE,SAAS,EAAE,YAAY,QAAQ,WAAW;AACjF,SAAS,QAAQ,EAAE,SAAS,EAAE,YAAY,EAAE,SAAS,EAAE,QAAQ,QAAQ,YAAY;AAEnF;AACA,OAAM,SAAU,cAAc,CAAC,OAAY,EAAiD;EAAA,IAA/C,YAAA,GAAA,SAAA,CAAA,MAAA,QAAA,SAAA,QAAA,SAAA,GAAA,SAAA,MAAsC,IAAI,GAAG,CAAA,CAAE;EACxF,OAAO,IAAI,MAAM,CACb,oBAAoB,CAAC,OAAO,EAAE,YAAY,CAAC,EAC3C,sBAAsB,CAAC,OAAO,CAAC,gBAAgB,CAAC,CAAC,EACjD,YAAY,CACf;AACL;AAEA;AACA,OAAM,SAAU,mBAAmB,CAAC,CAAM,EAAA;EACtC,OAAO,IAAI,WAAW,CAClB,CAAC,CAAC,OAAO,CAAC,EACV,kBAAkB,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,EAChC,eAAe,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAChC;AACL;AAEA;AACA,OAAM,SAAU,uBAAuB,CAAC,CAAM,EAAA;EAC1C,OAAO,IAAI,eAAe,CACtB,mBAAmB,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,EAC9B,CAAC,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,SAAS,CAAC,CACxB;AACL;AAEA;AACA,SAAS,oBAAoB,CAAC,OAAY,EAAE,YAAoC,EAAA;EAC5E,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,IAAI,EAAE,EAAE,MAAM,CAAC,OAAO,CAAC,CAAC,GAAG,CAAE,CAAM,IAAK,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;AACrG;AAEA;AACA,SAAS,qBAAqB,CAAC,MAAW,EAAE,YAAoC,EAAA;EAC5E,OAAO,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,EAAE,EAAE,MAAM,CAAC,OAAO,CAAC,CAAC,GAAG,CAAE,CAAM,IAAK,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;AACtG;AAEA;AACA,SAAS,kBAAkB,CAAC,EAAS,EAAA;EACjC,OAAO,CAAC,EAAE,IAAI,EAAE,EAAE,MAAM,CAAc,CAAC,UAAU,EAAE,MAAW,KAAK,CAC/D,GAAG,UAAU,EACb,IAAI,SAAS,CACT,MAAM,CAAC,OAAO,CAAC,EACf,iBAAiB,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,CACxC,EACD,GAAG,kBAAkB,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,CAC5C,EAAE,EAAiB,CAAC;AACzB;AAEA;AACA,SAAS,eAAe,CAAC,EAAS,EAA8B;EAAA,IAA5B,OAAA,GAAA,SAAA,CAAA,MAAA,QAAA,SAAA,QAAA,SAAA,GAAA,SAAA,MAA0B,EAAE;EAC5D,KAAK,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,IAAI,EAAE,EAAE,MAAM,EAAE,EAAE,CAAC,GAAG,CAAC,GAAG;IAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,CAAC,CAAC;IACpB,MAAM,CAAC,UAAU,CAAC,IAAI,OAAO,CAAC,IAAI,CAAC,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,CAAC;IAC/F,MAAM,CAAC,MAAM,CAAC,IAAI,OAAO,CAAC,IAAI,CAAC,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,CAAC;IACvF,MAAM,CAAC,QAAQ,CAAC,IAAI,OAAO,CAAC,IAAI,CAAC,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,QAAQ,CAAC,CAAC,MAAM,CAAC,CAAC;IAC3F,MAAM,CAAC,MAAM,CAAC,IAAI,OAAO,CAAC,IAAI,CAAC,IAAI,YAAY,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,CAAC;IACvF,OAAO,GAAG,eAAe,CAAC,MAAM,CAAC,UAAU,CAAC,EAAE,OAAO,CAAC;EACzD;EACD,OAAO,OAAO;AAClB;AAEA;AACA,SAAS,iBAAiB,CAAC,QAAkB,EAAA;EACzC,OAAO,CAAC,QAAQ,IAAI,EAAE,EAAE,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,KAAK,GAAG,GAAG,EAAE,GAAG,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;AACvE;AAEA;AACA,OAAM,SAAU,aAAa,CAAC,MAAW,EAAE,YAAoC,EAAA;EAE3E,IAAI,EAAU;EACd,IAAI,IAAkB;EACtB,IAAI,KAAmB;EACvB,IAAI,QAAa;EACjB,IAAI,IAAmB;EACvB,IAAI,QAAoB;EAExB;EACA,IAAI,CAAC,YAAY,IAAI,EAAE,QAAQ,GAAG,MAAM,CAAC,YAAY,CAAC,CAAC,EAAE;IACrD,IAAI,GAAG,YAAY,CAAC,MAAM,EAAE,qBAAqB,CAAC,MAAM,EAAE,YAAY,CAAC,CAAC;IACxE,KAAK,GAAG,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,MAAM,CAAC,UAAU,CAAC,EAAE,sBAAsB,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;EAChH;EACD;EACA;EACA;EACA;EAAA,KACK,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,EAAE,GAAG,QAAQ,CAAC,IAAI,CAAC,CAAC,EAAE;IAC7C;IACA,IAAI,GAAG,CAAC,IAAI,GAAG,QAAQ,CAAC,WAAW,CAAC,IAAI,iBAAiB,CAAC,IAAI,CAAU,GAAG,IAAI,KAAK,CAAA,CAAE;IACtF,YAAY,CAAC,GAAG,CAAC,EAAE,EAAE,IAAI,GAAG,YAAY,CAAC,MAAM,EAAE,qBAAqB,CAAC,MAAM,EAAE,YAAY,CAAC,CAAC,CAAC;IAC9F,QAAQ,GAAG,IAAI,UAAU,CAAC,IAAI,EAAE,IAAI,EAAE,EAAE,EAAE,QAAQ,CAAC,WAAW,CAAC,CAAC;IAChE,KAAK,GAAG,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,QAAQ,EAAE,MAAM,CAAC,UAAU,CAAC,EAAE,sBAAsB,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;EACpH;EACD;EACA;EAAA,KACK;IACD;IACA,IAAI,GAAG,CAAC,IAAI,GAAG,QAAQ,CAAC,WAAW,CAAC,IAAI,iBAAiB,CAAC,IAAI,CAAU,GAAG,IAAI,KAAK,CAAA,CAAE;IACtF,QAAQ,GAAG,IAAI,UAAU,CAAC,YAAY,CAAC,GAAG,CAAC,EAAE,CAAE,EAAE,IAAI,EAAE,EAAE,EAAE,QAAQ,CAAC,WAAW,CAAC,CAAC;IACjF,KAAK,GAAG,IAAI,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,QAAQ,EAAE,MAAM,CAAC,UAAU,CAAC,EAAE,sBAAsB,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC;EACpH;EACD,OAAO,KAAK,IAAI,IAAI;AACxB;AAEA;AACA,SAAS,sBAAsB,CAAC,SAAkB,EAAA;EAC9C,OAAO,IAAI,GAAG,CAAiB,MAAM,CAAC,OAAO,CAAC,SAAS,IAAI,CAAA,CAAE,CAAC,CAAC;AACnE;AAEA;AACA,SAAS,iBAAiB,CAAC,KAAU,EAAA;EACjC,OAAO,IAAI,GAAG,CAAC,KAAK,CAAC,UAAU,CAAC,EAAE,KAAK,CAAC,UAAU,CAAC,CAAC;AACxD;AAEA;AACA,SAAS,YAAY,CAAC,CAAM,EAAE,QAAkB,EAAA;EAE5C,MAAM,MAAM,GAAG,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC;EAEhC,QAAQ,MAAM;IACV,KAAK,MAAM;MAAI,OAAO,IAAI,IAAI,CAAA,CAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAI,IAAI,CAAA,CAAE;IAChC,KAAK,QAAQ;MAAE,OAAO,IAAI,MAAM,CAAA,CAAE;IAClC,KAAK,MAAM;MAAI,OAAO,IAAI,IAAI,CAAA,CAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAI,IAAI,CAAA,CAAE;IAChC,KAAK,MAAM;MAAI,OAAO,IAAI,IAAI,CAAC,CAAC,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;IACnD,KAAK,QAAQ;MAAE,OAAO,IAAI,MAAM,CAAC,QAAQ,IAAI,EAAE,CAAC;IAChD,KAAK,SAAS;MAAE,OAAO,IAAI,MAAM,CAAC,QAAQ,IAAI,EAAE,CAAC;EACpD;EAED,QAAQ,MAAM;IACV,KAAK,KAAK;MAAE;QACR,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,UAAU,CAAgB,CAAC;MAC9D;IACD,KAAK,eAAe;MAAE;QAClB,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC,WAAW,CAAC,CAAQ,CAAC;MACrD;IACD,KAAK,SAAS;MAAE;QACZ,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC,WAAW,CAAC,CAAC;MACjD;IACD,KAAK,MAAM;MAAE;QACT,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,KAAK,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;MAC/C;IACD,KAAK,MAAM;MAAE;QACT,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAE,CAAC,CAAC,UAAU,CAAiB,CAAC;MAC7E;IACD,KAAK,WAAW;MAAE;QACd,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,SAAS,CAAC,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAE,CAAC,CAAC,UAAU,CAAC,CAAC;MAClE;IACD,KAAK,UAAU;MAAE;QACb,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,QAAQ,CAAC,YAAY,CAAC,CAAC,CAAC,MAAM,CAAC,CAAQ,CAAC;MACtD;IACD,KAAK,OAAO;MAAE;QACV,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC,MAAM,CAAC,CAAQ,EAAG,CAAC,CAAC,SAAS,CAAC,IAAI,EAAE,EAAG,QAAQ,IAAI,EAAE,CAAC;MACtF;IACD,KAAK,iBAAiB;MAAE;QACpB,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,eAAe,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC;MAC7C;IACD,KAAK,eAAe;MAAE;QAClB,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,aAAa,CAAC,CAAC,CAAC,UAAU,CAAC,EAAE,CAAC,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,CAAC;MAC/D;IACD,KAAK,KAAK;MAAE;QACR,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,OAAO,IAAI,IAAI,CAAC,CAAC,QAAQ,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,YAAY,CAAC,CAAC;MACxD;EACJ;EACD,MAAM,IAAI,KAAK,yBAAA,MAAA,CAAwB,MAAM,OAAG,CAAC;AACrD","sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"]},"metadata":{},"sourceType":"module"}